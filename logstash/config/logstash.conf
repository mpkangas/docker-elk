input {
	tcp {
		port => 5000
	}
	beats {
    port => 5044
		tags => "IIS"
  }
	redis {
     host => redis1
     port => 6379
     data_type => "list"
     key => "logStash"
     db => "1"
		 tags => "win_service"
		 codec => "plain"
     # batch_count => 1
     # threads => 1
   }
}

## Add your filters / logstash plugins configuration here

filter {
	if "IIS" in [tags]
	{
		## Ignore the comments that IIS will add to the start of the W3C logs
	  #
		if [message] =~ "^#" {
			drop {}
		}

		grok {
	    ## Very helpful site for building these statements:
	    #   http://grokdebug.herokuapp.com/
	    #
	    # This is configured to parse out every field of IIS's W3C format when
	    #   every field is included in the logs
	    #
	    match => ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{WORD:serviceName} %{WORD:serverName} %{IP:serverIP} %{WORD:method} %{URIPATH:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clientIP} %{NOTSPACE:protocolVersion} %{NOTSPACE:userAgent} %{NOTSPACE:cookie} %{NOTSPACE:referer} %{NOTSPACE:requestHost} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:bytesSent} %{NUMBER:bytesReceived} %{NUMBER:timetaken}"]
	  }

		## Set the Event Timesteamp from the log
	  #
	  date {
	    match => [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ]
	      timezone => "Etc/UTC"
	  }

		## If the log record has a value for 'bytesSent', then add a new field
	  #   to the event that converts it to kilobytes
	  #
	  if [bytesSent] {
	    ruby {
	      code => "event.set('kilobytesSent',event.get('bytesSent').to_i / 1024.0)"
	    }
	  }

		## Do the same conversion for the bytes received value
	  #
	  if [bytesReceived] {
	    ruby {
	      code => "event.set('kilobytesReceived',event.get('bytesReceived').to_i / 1024.0)"
	    }
	  }

		## Making uriStem without GUID
		#
		if[uriStem] {
			mutate {
				add_field => { "action" => "%{uriStem}" }
			}
		}

		if[action] {
			mutate {
				gsub => ["action", "[{(]?[0-9a-fA-F]{8}[-]?([0-9a-fA-F]{4}[-]?){3}[0-9a-fA-F]{12}[)}]?","GUID"]
			}
		}


		## Perform some mutations on the records to prep them for Elastic
	  #
	  mutate {
	    ## Convert some fields from strings to integers
	    #
	    convert => ["bytesSent", "integer"]
	    convert => ["bytesReceived", "integer"]
	    convert => ["timetaken", "integer"]

	    ## Create a new field for the reverse DNS lookup below
	    #
	    add_field => { "clientHostname" => "%{clientIP}" }

	    ## Finally remove the original log_timestamp field since the event will
	    #   have the proper date on it
	    #
	    remove_field => [ "log_timestamp"]
		}

	}

	if "win_service" in [tags]
	{
		grok {
			 match => [ "message", "\A%{TIMESTAMP_ISO8601:timestamp}\|%{LOGLEVEL:level}\|%{JAVACLASS:class}%{GREEDYDATA:message}" ]
				 overwrite => [ "message" ]
			 }
		date {
		 match => [ "timestamp" , "yyyy-MM-dd HH:mm:ss.SSSS" ]
		}
		mutate {
				 gsub => [ "message", "|", "" ]
		}


	}

}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
	}
	file {
     path => "/var/log/logstash/output.log"
     }
}
